@misc{bevilacqua2022autoregressivesearchenginesgenerating,
      title={Autoregressive Search Engines: Generating Substrings as Document Identifiers}, 
      author={Michele Bevilacqua and Giuseppe Ottaviano and Patrick Lewis and Wen-tau Yih and Sebastian Riedel and Fabio Petroni},
      year={2022},
      eprint={2204.10628},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.10628}, 
}

@misc{massarelli2020decodingstrategiesaffectverifiability,
      title={How Decoding Strategies Affect the Verifiability of Generated Text}, 
      author={Luca Massarelli and Fabio Petroni and Aleksandra Piktus and Myle Ott and Tim Rocktäschel and Vassilis Plachouras and Fabrizio Silvestri and Sebastian Riedel},
      year={2020},
      eprint={1911.03587},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1911.03587}, 
}

@misc{li2024distillationenhancedgenerativeretrieval,
      title={Distillation Enhanced Generative Retrieval}, 
      author={Yongqi Li and Zhen Zhang and Wenjie Wang and Liqiang Nie and Wenjie Li and Tat-Seng Chua},
      year={2024},
      eprint={2402.10769},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10769}, 
}

@misc{bajaj2018msmarcohumangenerated,
      title={MS MARCO: A Human Generated MAchine Reading COmprehension Dataset}, 
      author={Payal Bajaj and Daniel Campos and Nick Craswell and Li Deng and Jianfeng Gao and Xiaodong Liu and Rangan Majumder and Andrew McNamara and Bhaskar Mitra and Tri Nguyen and Mir Rosenberg and Xia Song and Alina Stoica and Saurabh Tiwary and Tong Wang},
      year={2018},
      eprint={1611.09268},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1611.09268}, 
}

@misc{raffel2023exploringlimitstransferlearning,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2023},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.10683}, 
}

@INPROCEEDINGS{7410368,
author = { Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja },
booktitle = { 2015 IEEE International Conference on Computer Vision (ICCV) },
title = {{ Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books }},
year = {2015},
volume = {},
ISSN = {2380-7504},
pages = {19-27},
abstract = { Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for. },
keywords = {Motion pictures;Visualization;Videos;Semantics;Grounding;Voltage control;Roads},
doi = {10.1109/ICCV.2015.11},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV.2015.11},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Dec}


@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026/",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature."
}

@article{Metzler_2021,
   title={Rethinking search: making domain experts out of dilettantes},
   volume={55},
   ISSN={0163-5840},
   url={http://dx.doi.org/10.1145/3476415.3476428},
   DOI={10.1145/3476415.3476428},
   number={1},
   journal={ACM SIGIR Forum},
   publisher={Association for Computing Machinery (ACM)},
   author={Metzler, Donald and Tay, Yi and Bahri, Dara and Najork, Marc},
   year={2021},
   month=jun, pages={1–27} }

@article{Ji_2023,
   title={Survey of Hallucination in Natural Language Generation},
   volume={55},
   ISSN={1557-7341},
   url={http://dx.doi.org/10.1145/3571730},
   DOI={10.1145/3571730},
   number={12},
   journal={ACM Computing Surveys},
   publisher={Association for Computing Machinery (ACM)},
   author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
   year={2023},
   month=mar, pages={1–38} }

@misc{zeng2024planningaheadgenerativeretrieval,
      title={Planning Ahead in Generative Retrieval: Guiding Autoregressive Generation through Simultaneous Decoding}, 
      author={Hansi Zeng and Chen Luo and Hamed Zamani},
      year={2024},
      eprint={2404.14600},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2404.14600}, 
}

@misc{zhang2024generativeretrievaltermset,
      title={Generative Retrieval via Term Set Generation}, 
      author={Peitian Zhang and Zheng Liu and Yujia Zhou and Zhicheng Dou and Fangchao Liu and Zhao Cao},
      year={2024},
      eprint={2305.13859},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2305.13859}, 
}

@misc{stahlberg2019nmtsearcherrorsmodel,
      title={On NMT Search Errors and Model Errors: Cat Got Your Tongue?}, 
      author={Felix Stahlberg and Bill Byrne},
      year={2019},
      eprint={1908.10090},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1908.10090}, 
}

@inproceedings{Zhou2005BeamStackSI,
  title={Beam-Stack Search: Integrating Backtracking with Beam Search},
  author={R. Zhou and Eric A. Hansen},
  booktitle={International Conference on Automated Planning and Scheduling},
  year={2005},
  url={https://api.semanticscholar.org/CorpusID:11314454}
}

@misc{sun2023learningtokenizegenerativeretrieval,
      title={Learning to Tokenize for Generative Retrieval}, 
      author={Weiwei Sun and Lingyong Yan and Zheng Chen and Shuaiqiang Wang and Haichao Zhu and Pengjie Ren and Zhumin Chen and Dawei Yin and Maarten de Rijke and Zhaochun Ren},
      year={2023},
      eprint={2304.04171},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2304.04171}, 
}

@inproceedings{Chen_2023, series={CIKM ’23},
   title={Continual Learning for Generative Retrieval over Dynamic Corpora},
   url={http://dx.doi.org/10.1145/3583780.3614821},
   DOI={10.1145/3583780.3614821},
   booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
   publisher={ACM},
   author={Chen, Jiangui and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
   year={2023},
   month=oct, pages={306–315},
   collection={CIKM ’23} }


@misc{zhang2025replicationexplorationgenerativeretrieval,
      title={Replication and Exploration of Generative Retrieval over Dynamic Corpora}, 
      author={Zhen Zhang and Xinyu Ma and Weiwei Sun and Pengjie Ren and Zhumin Chen and Shuaiqiang Wang and Dawei Yin and Maarten de Rijke and Zhaochun Ren},
      year={2025},
      eprint={2504.17519},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2504.17519}, 
}

@misc{liu2024robustnessgenerativeinformationretrieval,
      title={On the Robustness of Generative Information Retrieval Models}, 
      author={Yu-An Liu and Ruqing Zhang and Jiafeng Guo and Changjiang Zhou and Maarten de Rijke and Xueqi Cheng},
      year={2024},
      eprint={2412.18768},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2412.18768}, 
}

@misc{yuan2024generativedenseretrievalmemory,
      title={Generative Dense Retrieval: Memory Can Be a Burden}, 
      author={Peiwen Yuan and Xinglin Wang and Shaoxiong Feng and Boyuan Pan and Yiwei Li and Heda Wang and Xupeng Miao and Kan Li},
      year={2024},
      eprint={2401.10487},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2401.10487}, 
}

@misc{pradeep2023doesgenerativeretrievalscale,
      title={How Does Generative Retrieval Scale to Millions of Passages?}, 
      author={Ronak Pradeep and Kai Hui and Jai Gupta and Adam D. Lelkes and Honglei Zhuang and Jimmy Lin and Donald Metzler and Vinh Q. Tran},
      year={2023},
      eprint={2305.11841},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2305.11841}, 
}

@misc{tay2022transformermemorydifferentiablesearch,
      title={Transformer Memory as a Differentiable Search Index}, 
      author={Yi Tay and Vinh Q. Tran and Mostafa Dehghani and Jianmo Ni and Dara Bahri and Harsh Mehta and Zhen Qin and Kai Hui and Zhe Zhao and Jai Gupta and Tal Schuster and William W. Cohen and Donald Metzler},
      year={2022},
      eprint={2202.06991},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.06991}, 
}

@misc{mehta2023dsiupdatingtransformermemory,
      title={DSI++: Updating Transformer Memory with New Documents}, 
      author={Sanket Vaibhav Mehta and Jai Gupta and Yi Tay and Mostafa Dehghani and Vinh Q. Tran and Jinfeng Rao and Marc Najork and Emma Strubell and Donald Metzler},
      year={2023},
      eprint={2212.09744},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.09744}, 
}

@misc{nguyen2023generativeretrievaldenseretrieval,
      title={Generative Retrieval as Dense Retrieval}, 
      author={Thong Nguyen and Andrew Yates},
      year={2023},
      eprint={2306.11397},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2306.11397}, 
}

@misc{zeng2023scalableeffectivegenerativeinformation,
      title={Scalable and Effective Generative Information Retrieval}, 
      author={Hansi Zeng and Chen Luo and Bowen Jin and Sheikh Muhammad Sarwar and Tianxin Wei and Hamed Zamani},
      year={2023},
      eprint={2311.09134},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2311.09134}, 
}

@inproceedings{10.1145/3589335.3641239,
author = {Tang, Yubao and Zhang, Ruqing and Sun, Weiwei and Guo, Jiafeng and De Rijke, Maarten},
title = {Recent Advances in Generative Information Retrieval},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641239},
doi = {10.1145/3589335.3641239},
abstract = {Generative retrieval (GR) has witnessed significant growth recently in the area of information retrieval. Compared to the traditional "index-retrieve-then-rank'' pipeline, the GR paradigm aims to consolidate all information within a corpus into a single model. Typically, a sequence-to-sequence model is trained to directly map a query to its relevant document identifiers (i.e., docids). This tutorial offers an introduction to the core concepts of the GR paradigm and a comprehensive overview of recent advances in its foundations and applications. We start by providing preliminary information covering foundational aspects and problem formulations of GR. Then, our focus shifts towards recent progress in docid design, training approaches, inference strategies, and applications of GR. We end by outlining challenges and issuing a call for future GR research.This tutorial is intended to be beneficial to both researchers and industry practitioners interested in developing novel GR solutions or applying them in real-world scenarios.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1238–1241},
numpages = {4},
location = {Singapore, Singapore},
series = {WWW '24}
}

@misc{ross2021evaluatinginterpretabilitygenerativemodels,
      title={Evaluating the Interpretability of Generative Models by Interactive Reconstruction}, 
      author={Andrew Slavin Ross and Nina Chen and Elisa Zhao Hang and Elena L. Glassman and Finale Doshi-Velez},
      year={2021},
      eprint={2102.01264},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2102.01264}, 
}

@misc{li2025matchinggenerationsurveygenerative,
      title={From Matching to Generation: A Survey on Generative Information Retrieval}, 
      author={Xiaoxi Li and Jiajie Jin and Yujia Zhou and Yuyao Zhang and Peitian Zhang and Yutao Zhu and Zhicheng Dou},
      year={2025},
      eprint={2404.14851},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2404.14851}, 
}

@misc{kuo2024surveygenerativeinformationretrieval,
      title={A Survey of Generative Information Retrieval}, 
      author={Tzu-Lin Kuo and Tzu-Wei Chiu and Tzung-Sheng Lin and Sheng-Yang Wu and Chao-Wei Huang and Yun-Nung Chen},
      year={2024},
      eprint={2406.01197},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2406.01197}, 
}

@misc{tang2024listwisegenerativeretrievalmodels,
      title={Listwise Generative Retrieval Models via a Sequential Learning Process}, 
      author={Yubao Tang and Ruqing Zhang and Jiafeng Guo and Maarten de Rijke and Wei Chen and Xueqi Cheng},
      year={2024},
      eprint={2403.12499},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2403.12499}, 
}

@misc{yang2023autosearchindexerendtoend,
      title={Auto Search Indexer for End-to-End Document Retrieval}, 
      author={Tianchi Yang and Minghui Song and Zihan Zhang and Haizhen Huang and Weiwei Deng and Feng Sun and Qi Zhang},
      year={2023},
      eprint={2310.12455},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2310.12455}, 
}

@article{10.1145/3603167,
author = {Zhou, Yujia and Yao, Jing and Dou, Zhicheng and Tu, Yiteng and Wu, Ledell and Chua, Tat-Seng and Wen, Ji-Rong},
title = {ROGER: Ranking-Oriented Generative Retrieval},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3603167},
doi = {10.1145/3603167},
abstract = {In recent years, various dense retrieval methods have been developed to improve the performance of search engines with a vectorized index. However, these approaches require a large pre-computed index and have a limited capacity to memorize all semantics in a document within a single vector. To address these issues, researchers have explored end-to-end generative retrieval models that use a seq-to-seq generative model to directly return identifiers of relevant documents. Although these models have been effective, they are often trained with the MLE method. It only encourages the model to assign a high probability to the relevant document identifier, ignoring the relevance comparisons of other documents. This may lead to performance degradation in ranking tasks, where the core is to compare the relevance between documents. To address this issue, we propose a ranking-oriented generative retrieval model that incorporates relevance signals to better estimate the relative relevance of different documents in ranking tasks. Based upon the analysis of the optimization objectives of dense retrieval and generative retrieval, we propose utilizing dense retrieval to provide relevance feedback for generative retrieval. Under an alternate training framework, the generative retrieval model gradually acquires higher-quality ranking signals to optimize the model. Experimental results show that our approach increasing Recall@1 by 12.9\% with respect to the baselines on MS MARCO dataset.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
articleno = {155},
numpages = {25},
keywords = {Model-based IR, generative model, document retrieval, knowledge distillation, docid representation}
}

@misc{li2023multiviewidentifiersenhancedgenerative,
      title={Multiview Identifiers Enhanced Generative Retrieval}, 
      author={Yongqi Li and Nan Yang and Liang Wang and Furu Wei and Wenjie Li},
      year={2023},
      eprint={2305.16675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.16675}, 
}

@misc{li2023learningrankgenerativeretrieval,
      title={Learning to Rank in Generative Retrieval}, 
      author={Yongqi Li and Nan Yang and Liang Wang and Furu Wei and Wenjie Li},
      year={2023},
      eprint={2306.15222},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.15222}, 
}

@misc{tang2024generativeretrievalmeetsmultigraded,
      title={Generative Retrieval Meets Multi-Graded Relevance}, 
      author={Yubao Tang and Ruqing Zhang and Jiafeng Guo and Maarten de Rijke and Wei Chen and Xueqi Cheng},
      year={2024},
      eprint={2409.18409},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2409.18409}, 
}

@inproceedings{Choi_2022, series={CIKM ’22},
   title={SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval},
   url={http://dx.doi.org/10.1145/3511808.3557456},
   DOI={10.1145/3511808.3557456},
   booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
   publisher={ACM},
   author={Choi, Eunseong and Lee, Sunkyung and Choi, Minjin and Ko, Hyeseon and Song, Young-In and Lee, Jongwuk},
   year={2022},
   month=oct, pages={272–282},
   collection={CIKM ’22} }

@misc{biswas2024efficientinterpretableinformationretrieval,
      title={Efficient and Interpretable Information Retrieval for Product Question Answering with Heterogeneous Data}, 
      author={Biplob Biswas and Rajiv Ramnath},
      year={2024},
      eprint={2405.13173},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.13173}, 
}

@misc{gao2021coilrevisitexactlexical,
      title={COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List}, 
      author={Luyu Gao and Zhuyun Dai and Jamie Callan},
      year={2021},
      eprint={2104.07186},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2104.07186}, 
}

@misc{karpukhin2020densepassageretrievalopendomain,
      title={Dense Passage Retrieval for Open-Domain Question Answering}, 
      author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
      year={2020},
      eprint={2004.04906},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.04906}, 
}

@misc{xiong2020approximatenearestneighbornegative,
      title={Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval}, 
      author={Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul Bennett and Junaid Ahmed and Arnold Overwijk},
      year={2020},
      eprint={2007.00808},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2007.00808}, 
}

@misc{li2023constructingtreebasedindexefficient,
      title={Constructing Tree-based Index for Efficient and Effective Dense Retrieval}, 
      author={Haitao Li and Qingyao Ai and Jingtao Zhan and Jiaxin Mao and Yiqun Liu and Zheng Liu and Zhao Cao},
      year={2023},
      eprint={2304.11943},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2304.11943}, 
}

@misc{ni2021largedualencodersgeneralizable,
      title={Large Dual Encoders Are Generalizable Retrievers}, 
      author={Jianmo Ni and Chen Qu and Jing Lu and Zhuyun Dai and Gustavo Hernández Ábrego and Ji Ma and Vincent Y. Zhao and Yi Luan and Keith B. Hall and Ming-Wei Chang and Yinfei Yang},
      year={2021},
      eprint={2112.07899},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2112.07899}, 
}

@misc{liu2019robertarobustlyoptimizedbert,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1907.11692}, 
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{naous2024havingbeerprayermeasuring,
      title={Having Beer after Prayer? Measuring Cultural Bias in Large Language Models}, 
      author={Tarek Naous and Michael J. Ryan and Alan Ritter and Wei Xu},
      year={2024},
      eprint={2305.14456},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14456}, 
}

@misc{aowal2023detectingnaturallanguagebiases,
      title={Detecting Natural Language Biases with Prompt-based Learning}, 
      author={Md Abdul Aowal and Maliha T Islam and Priyanka Mary Mammen and Sandesh Shetty},
      year={2023},
      eprint={2309.05227},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.05227}, 
}

@article{10.1145/3597307,
author = {Navigli, Roberto and Conia, Simone and Ross, Bj\"{o}rn},
title = {Biases in Large Language Models: Origins, Inventory, and Discussion},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1936-1955},
url = {https://doi.org/10.1145/3597307},
doi = {10.1145/3597307},
abstract = {In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.},
journal = {J. Data and Information Quality},
month = jun,
articleno = {10},
numpages = {21},
keywords = {language models, Bias in NLP}
}

@inproceedings{joshi-etal-2017-triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147/",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study."
}

@misc{petroni2021kiltbenchmarkknowledgeintensive,
      title={KILT: a Benchmark for Knowledge Intensive Language Tasks}, 
      author={Fabio Petroni and Aleksandra Piktus and Angela Fan and Patrick Lewis and Majid Yazdani and Nicola De Cao and James Thorne and Yacine Jernite and Vladimir Karpukhin and Jean Maillard and Vassilis Plachouras and Tim Rocktäschel and Sebastian Riedel},
      year={2021},
      eprint={2009.02252},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.02252}, 
}