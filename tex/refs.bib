@inproceedings{
TODO,
title={TODO},
author={TODO},
booktitle={TODO},
editor={TODO},
year={TODO},
url={TODO}
}

@inproceedings{
bevilacqua2022autoregressivesearchenginesgenerating,
title={Autoregressive Search Engines: Generating Substrings as Document Identifiers},
author={Michele Bevilacqua and Giuseppe Ottaviano and Patrick Lewis and Scott Yih and Sebastian Riedel and Fabio Petroni},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=Z4kZxAjg8Y}
}

@inproceedings{lewis-etal-2020-bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.703/",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
    abstract = "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance."
}

@inproceedings{massarelli2020decodingstrategiesaffectverifiability,
    title = "How Decoding Strategies Affect the Verifiability of Generated Text",
    author = {Massarelli, Luca and Petroni, Fabio and Piktus, Aleksandra and Ott, Myle and Rockt{\"a}schel, Tim and Plachouras, Vassilis and Silvestri, Fabrizio and Riedel, Sebastian},
    editor = "Cohn, Trevor and He, Yulan and Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.22/",
    doi = "10.18653/v1/2020.findings-emnlp.22",
    pages = "223--235",
    abstract = "Recent progress in pre-trained language models led to systems that are able to generate text of an increasingly high quality. While several works have investigated the fluency and grammatical correctness of such models, it is still unclear to which extent the generated text is consistent with factual world knowledge. Here, we go beyond fluency and also investigate the verifiability of text generated by state-of-the-art pre-trained language models. A generated sentence is verifiable if it can be corroborated or disproved by Wikipedia, and we find that the verifiability of generated text strongly depends on the decoding strategy. In particular, we discover a tradeoff between factuality (i.e., the ability of generating Wikipedia corroborated text) and repetitiveness. While decoding strategies such as top-k and nucleus sampling lead to less repetitive generations, they also produce less verifiable text. Based on these finding, we introduce a simple and effective decoding strategy which, in comparison to previously used decoding strategies, produces less repetitive and more verifiable text."
}

@inproceedings{li2024distillationenhancedgenerativeretrieval,
    title = "Distillation Enhanced Generative Retrieval",
    author = "Li, Yongqi and Zhang, Zhen and Wang, Wenjie and Nie, Liqiang and Li, Wenjie and Chua, Tat-Seng",
    editor = "Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.662/",
    doi = "10.18653/v1/2024.findings-acl.662",
    pages = "11119--11129",
    abstract = "Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generative language models, distinct from traditional sparse or dense retrieval methods. In this work, we identify a viable direction to further enhance generative retrieval via distillation and propose a feasible framework, named DGR. DGR utilizes sophisticated ranking models, such as the cross-encoder, in a teacher role to supply a passage rank list, which captures the varying relevance degrees of passages instead of binary hard labels; subsequently, DGR employs a specially designed distilled RankNet loss to optimize the generative retrieval model, considering the passage rank order provided by the teacher model as labels. This framework only requires an additional distillation step to enhance current generative retrieval systems and does not add any burden to the inference stage. We conduct experiments on four public datasets, and the results indicate that DGR achieves state-of-the-art performance among the generative retrieval methods. Additionally, DGR demonstrates exceptional robustness and generalizability with various teacher models and distillation losses."
}

@misc{decao2021autoregressiveentityretrieval,
 title={Autoregressive Entity Retrieval}, 
 author={Nicola De Cao and Gautier Izacard and Sebastian Riedel and Fabio Petroni},
 year={2021},
 eprint={2010.00904},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2010.00904}, 
}

@article{10.1145/362686.362692,
author = {Bloom, Burton H.},
title = {Space/time trade-offs in hash coding with allowable errors},
year = {1970},
issue_date = {July 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/362686.362692},
doi = {10.1145/362686.362692},
abstract = {In this paper trade-offs among certain computational factors in hash coding are analyzed. The paradigm problem considered is that of testing a series of messages one-by-one for membership in a given set of messages. Two new hash-coding methods are examined and compared with a particular conventional hash-coding method. The computational factors considered are the size of the hash area (space), the time required to identify a message as a nonmember of the given set (reject time), and an allowable error frequency.The new methods are intended to reduce the amount of space required to contain the hash-coded information from that associated with conventional methods. The reduction in space is accomplished by exploiting the possibility that a small fraction of errors of commission may be tolerable in some applications, in particular, applications in which a large amount of data is involved and a core resident hash area is consequently not feasible using conventional methods.In such applications, it is envisaged that overall performance could be improved by using a smaller core resident hash area in conjunction with the new methods and, when necessary, by using some secondary and perhaps time-consuming test to “catch” the small fraction of errors associated with the new methods. An example is discussed which illustrates possible areas of application for the new methods.Analysis of the paradigm problem demonstrates that allowing a small number of test messages to be falsely identified as members of the given set will permit a much smaller hash area to be used without increasing reject time.},
journal = {Commun. ACM},
month = jul,
pages = {422–426},
numpages = {5},
keywords = {hash addressing, hash coding, retrieval efficiency, retrieval trade-offs, scatter storage, searching, storage efficiency, storage layout}
}

@misc{bajaj2018msmarcohumangenerated,
 title={MS MARCO: A Human Generated MAchine Reading COmprehension Dataset}, 
 author={Payal Bajaj and Daniel Campos and Nick Craswell and Li Deng and Jianfeng Gao and Xiaodong Liu and Rangan Majumder and Andrew McNamara and Bhaskar Mitra and Tri Nguyen and Mir Rosenberg and Xia Song and Alina Stoica and Saurabh Tiwary and Tong Wang},
 year={2018},
 eprint={1611.09268},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/1611.09268}, 
}

@article{t5-raffel2023exploringlimitstransferlearning,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@INPROCEEDINGS{7410368,
author = { Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja },
booktitle = { 2015 IEEE International Conference on Computer Vision (ICCV) },
title = {{ Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books }},
year = {2015},
volume = {},
ISSN = {2380-7504},
pages = {19-27},
abstract = { Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for. },
keywords = {Motion pictures;Visualization;Videos;Semantics;Grounding;Voltage control;Roads},
doi = {10.1109/ICCV.2015.11},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV.2015.11},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Dec}


@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and Toutanova, Kristina and Jones, Llion and Kelcey, Matthew and Chang, Ming-Wei and Dai, Andrew M.and Uszkoreit, Jakob and Le, Quoc and Petrov, Slav",
    editor = "Lee, Lillian and Johnson, Mark and Roark, Brian and Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026/",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature."
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423/",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
}

@article{Metzler_2021,
   title={Rethinking search: making domain experts out of dilettantes},
   volume={55},
   ISSN={0163-5840},
   url={http://dx.doi.org/10.1145/3476415.3476428},
   DOI={10.1145/3476415.3476428},
   number={1},
   journal={ACM SIGIR Forum},
   publisher={Association for Computing Machinery (ACM)},
   author={Metzler, Donald and Tay, Yi and Bahri, Dara and Najork, Marc},
   year={2021},
   month=jun, pages={1–27} }

@article{Ji_2023,
   title={Survey of Hallucination in Natural Language Generation},
   volume={55},
   ISSN={1557-7341},
   url={http://dx.doi.org/10.1145/3571730},
   DOI={10.1145/3571730},
   number={12},
   journal={ACM Computing Surveys},
   publisher={Association for Computing Machinery (ACM)},
   author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
   year={2023},
   month=mar, pages={1–38} }

@misc{zeng2024planningaheadgenerativeretrieval,
 title={Planning Ahead in Generative Retrieval: Guiding Autoregressive Generation through Simultaneous Decoding}, 
 author={Hansi Zeng and Chen Luo and Hamed Zamani},
 year={2024},
 eprint={2404.14600},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2404.14600}, 
}

@misc{zhang2024generativeretrievaltermset,
 title={Generative Retrieval via Term Set Generation}, 
 author={Peitian Zhang and Zheng Liu and Yujia Zhou and Zhicheng Dou and Fangchao Liu and Zhao Cao},
 year={2024},
 eprint={2305.13859},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2305.13859}, 
}

@misc{stahlberg2019nmtsearcherrorsmodel,
 title={On NMT Search Errors and Model Errors: Cat Got Your Tongue?}, 
 author={Felix Stahlberg and Bill Byrne},
 year={2019},
 eprint={1908.10090},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/1908.10090}, 
}

@inproceedings{Zhou2005BeamStackSI,
  title={Beam-Stack Search: Integrating Backtracking with Beam Search},
  author={R. Zhou and Eric A. Hansen},
  booktitle={International Conference on Automated Planning and Scheduling},
  year={2005},
  url={https://api.semanticscholar.org/CorpusID:11314454}
}

@misc{sun2023learningtokenizegenerativeretrieval,
 title={Learning to Tokenize for Generative Retrieval}, 
 author={Weiwei Sun and Lingyong Yan and Zheng Chen and Shuaiqiang Wang and Haichao Zhu and Pengjie Ren and Zhumin Chen and Dawei Yin and Maarten de Rijke and Zhaochun Ren},
 year={2023},
 eprint={2304.04171},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2304.04171}, 
}

@inproceedings{Chen_2023, series={CIKM ’23},
   title={Continual Learning for Generative Retrieval over Dynamic Corpora},
   url={http://dx.doi.org/10.1145/3583780.3614821},
   DOI={10.1145/3583780.3614821},
   booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
   publisher={ACM},
   author={Chen, Jiangui and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
   year={2023},
   month=oct, pages={306–315},
   collection={CIKM ’23} }


@misc{zhang2025replicationexplorationgenerativeretrieval,
 title={Replication and Exploration of Generative Retrieval over Dynamic Corpora}, 
 author={Zhen Zhang and Xinyu Ma and Weiwei Sun and Pengjie Ren and Zhumin Chen and Shuaiqiang Wang and Dawei Yin and Maarten de Rijke and Zhaochun Ren},
 year={2025},
 eprint={2504.17519},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2504.17519}, 
}

@misc{liu2024robustnessgenerativeinformationretrieval,
 title={On the Robustness of Generative Information Retrieval Models}, 
 author={Yu-An Liu and Ruqing Zhang and Jiafeng Guo and Changjiang Zhou and Maarten de Rijke and Xueqi Cheng},
 year={2024},
 eprint={2412.18768},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2412.18768}, 
}

@misc{wang2023neuralcorpusindexerdocument,
 title={A Neural Corpus Indexer for Document Retrieval}, 
 author={Yujing Wang and Yingyan Hou and Haonan Wang and Ziming Miao and Shibin Wu and Hao Sun and Qi Chen and Yuqing Xia and Chengmin Chi and Guoshuai Zhao and Zheng Liu and Xing Xie and Hao Allen Sun and Weiwei Deng and Qi Zhang and Mao Yang},
 year={2023},
 eprint={2206.02743},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2206.02743}, 
}

@misc{yuan2024generativedenseretrievalmemory,
 title={Generative Dense Retrieval: Memory Can Be a Burden}, 
 author={Peiwen Yuan and Xinglin Wang and Shaoxiong Feng and Boyuan Pan and Yiwei Li and Heda Wang and Xupeng Miao and Kan Li},
 year={2024},
 eprint={2401.10487},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2401.10487}, 
}

@misc{pradeep2023doesgenerativeretrievalscale,
 title={How Does Generative Retrieval Scale to Millions of Passages?}, 
 author={Ronak Pradeep and Kai Hui and Jai Gupta and Adam D. Lelkes and Honglei Zhuang and Jimmy Lin and Donald Metzler and Vinh Q. Tran},
 year={2023},
 eprint={2305.11841},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2305.11841}, 
}

@misc{tay2022transformermemorydifferentiablesearch,
 title={Transformer Memory as a Differentiable Search Index}, 
 author={Yi Tay and Vinh Q. Tran and Mostafa Dehghani and Jianmo Ni and Dara Bahri and Harsh Mehta and Zhen Qin and Kai Hui and Zhe Zhao and Jai Gupta and Tal Schuster and William W. Cohen and Donald Metzler},
 year={2022},
 eprint={2202.06991},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2202.06991}, 
}

@inproceedings{splade10.1145/3404835.3463098,
author = {Formal, Thibault and Piwowarski, Benjamin and Clinchant, St\'{e}phane},
title = {SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463098},
doi = {10.1145/3404835.3463098},
abstract = {In neural Information Retrieval, ongoing research is directed towards improving the first retriever in ranking pipelines. Learning dense embeddings to conduct retrieval using efficient approximate nearest neighbors methods has proven to work well. Meanwhile, there has been a growing interest in learning sparse representations for documents and queries, that could inherit from the desirable properties of bag-of-words models such as the exact matching of terms and the efficiency of inverted indexes. In this work, we present a new first-stage ranker based on explicit sparsity regularization and a log-saturation effect on term weights, leading to highly sparse representations and competitive results with respect to state-of-the-art dense and sparse methods. Our approach is simple, trained end-to-end in a single stage. We also explore the trade-off between effectiveness and efficiency, by controlling the contribution of the sparsity regularization.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2288–2292},
numpages = {5},
keywords = {indexing, neural networks, regularization, sparse representations},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@inproceedings{10.1145/3726302.3730076,
author = {Reusch, Anja and Belinkov, Yonatan},
title = {Reverse-Engineering the Retrieval Process in GenIR Models},
year = {2025},
isbn = {9798400715921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726302.3730076},
doi = {10.1145/3726302.3730076},
abstract = {Generative Information Retrieval (GenIR) is a novel paradigm in which a transformer encoder-decoder model predicts document rankings based on a query in an end-to-end fashion. These GenIR models have received significant attention due to their simple retrieval architecture while maintaining high retrieval effectiveness. However, in contrast to established retrieval architectures like cross-encoders or bi-encoders, their internal computations remain largely unknown. In this work, we investigate this retrieval mechanism and uncover the roles played by different model components (self-attention, cross-attention, MLPs) and their interaction to generate the document identifier. First, we show that the pre-trained encoder, which was not fine-tuned for retrieval, is sufficient for the retrieval process. Then, we find that the pass through the decoder can be divided into three stages: (I) the priming stage in which no component contributes query-specific information (II) the bridging stage where cross-attention transfers query information from the encoder to the decoder, and (III) the interaction stage where MLPs process this transferred information to predict the document identifier in the last layer. Our results indicate that document-specific information is only stored in a few components in the final stage of the retrieval process. We hope that our findings will motivate the development of more effective GenIR models and facilitate their improvements.},
booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {668–677},
numpages = {10},
keywords = {generative information retrieval, interpretability, neural information retrieval},
location = {Padua, Italy},
series = {SIGIR '25}
}

@misc{mehta2023dsiupdatingtransformermemory,
 title={DSI++: Updating Transformer Memory with New Documents}, 
 author={Sanket Vaibhav Mehta and Jai Gupta and Yi Tay and Mostafa Dehghani and Vinh Q. Tran and Jinfeng Rao and Marc Najork and Emma Strubell and Donald Metzler},
 year={2023},
 eprint={2212.09744},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2212.09744}, 
}

@misc{nguyen2023generativeretrievaldenseretrieval,
 title={Generative Retrieval as Dense Retrieval}, 
 author={Thong Nguyen and Andrew Yates},
 year={2023},
 eprint={2306.11397},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2306.11397}, 
}

@misc{zeng2023scalableeffectivegenerativeinformation,
 title={Scalable and Effective Generative Information Retrieval}, 
 author={Hansi Zeng and Chen Luo and Bowen Jin and Sheikh Muhammad Sarwar and Tianxin Wei and Hamed Zamani},
 year={2023},
 eprint={2311.09134},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2311.09134}, 
}

@inproceedings{10.1145/3589335.3641239,
author = {Tang, Yubao and Zhang, Ruqing and Sun, Weiwei and Guo, Jiafeng and De Rijke, Maarten},
title = {Recent Advances in Generative Information Retrieval},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641239},
doi = {10.1145/3589335.3641239},
abstract = {Generative retrieval (GR) has witnessed significant growth recently in the area of information retrieval. Compared to the traditional "index-retrieve-then-rank'' pipeline, the GR paradigm aims to consolidate all information within a corpus into a single model. Typically, a sequence-to-sequence model is trained to directly map a query to its relevant document identifiers (i.e., docids). This tutorial offers an introduction to the core concepts of the GR paradigm and a comprehensive overview of recent advances in its foundations and applications. We start by providing preliminary information covering foundational aspects and problem formulations of GR. Then, our focus shifts towards recent progress in docid design, training approaches, inference strategies, and applications of GR. We end by outlining challenges and issuing a call for future GR research.This tutorial is intended to be beneficial to both researchers and industry practitioners interested in developing novel GR solutions or applying them in real-world scenarios.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1238–1241},
numpages = {4},
location = {Singapore, Singapore},
series = {WWW '24}
}

@misc{ross2021evaluatinginterpretabilitygenerativemodels,
 title={Evaluating the Interpretability of Generative Models by Interactive Reconstruction}, 
 author={Andrew Slavin Ross and Nina Chen and Elisa Zhao Hang and Elena L. Glassman and Finale Doshi-Velez},
 year={2021},
 eprint={2102.01264},
 archivePrefix={arXiv},
 primaryClass={cs.LG},
 url={https://arxiv.org/abs/2102.01264}, 
}

@misc{li2025matchinggenerationsurveygenerative,
 title={From Matching to Generation: A Survey on Generative Information Retrieval}, 
 author={Xiaoxi Li and Jiajie Jin and Yujia Zhou and Yuyao Zhang and Peitian Zhang and Yutao Zhu and Zhicheng Dou},
 year={2025},
 eprint={2404.14851},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2404.14851}, 
}

@misc{kuo2024surveygenerativeinformationretrieval,
 title={A Survey of Generative Information Retrieval}, 
 author={Tzu-Lin Kuo and Tzu-Wei Chiu and Tzung-Sheng Lin and Sheng-Yang Wu and Chao-Wei Huang and Yun-Nung Chen},
 year={2024},
 eprint={2406.01197},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2406.01197}, 
}

@misc{tang2024listwisegenerativeretrievalmodels,
 title={Listwise Generative Retrieval Models via a Sequential Learning Process}, 
 author={Yubao Tang and Ruqing Zhang and Jiafeng Guo and Maarten de Rijke and Wei Chen and Xueqi Cheng},
 year={2024},
 eprint={2403.12499},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2403.12499}, 
}

@misc{tang2023semanticenhanceddifferentiablesearchindex,
      title={Semantic-Enhanced Differentiable Search Index Inspired by Learning Strategies}, 
      author={Yubao Tang and Ruqing Zhang and Jiafeng Guo and Jiangui Chen and Zuowei Zhu and Shuaiqiang Wang and Dawei Yin and Xueqi Cheng},
      year={2023},
      eprint={2305.15115},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2305.15115}, 
}

@misc{yang2023autosearchindexerendtoend,
 title={Auto Search Indexer for End-to-End Document Retrieval}, 
 author={Tianchi Yang and Minghui Song and Zihan Zhang and Haizhen Huang and Weiwei Deng and Feng Sun and Qi Zhang},
 year={2023},
 eprint={2310.12455},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2310.12455}, 
}

@article{10.1145/3603167,
author = {Zhou, Yujia and Yao, Jing and Dou, Zhicheng and Tu, Yiteng and Wu, Ledell and Chua, Tat-Seng and Wen, Ji-Rong},
title = {ROGER: Ranking-Oriented Generative Retrieval},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3603167},
doi = {10.1145/3603167},
abstract = {In recent years, various dense retrieval methods have been developed to improve the performance of search engines with a vectorized index. However, these approaches require a large pre-computed index and have a limited capacity to memorize all semantics in a document within a single vector. To address these issues, researchers have explored end-to-end generative retrieval models that use a seq-to-seq generative model to directly return identifiers of relevant documents. Although these models have been effective, they are often trained with the MLE method. It only encourages the model to assign a high probability to the relevant document identifier, ignoring the relevance comparisons of other documents. This may lead to performance degradation in ranking tasks, where the core is to compare the relevance between documents. To address this issue, we propose a ranking-oriented generative retrieval model that incorporates relevance signals to better estimate the relative relevance of different documents in ranking tasks. Based upon the analysis of the optimization objectives of dense retrieval and generative retrieval, we propose utilizing dense retrieval to provide relevance feedback for generative retrieval. Under an alternate training framework, the generative retrieval model gradually acquires higher-quality ranking signals to optimize the model. Experimental results show that our approach increasing Recall@1 by 12.9\% with respect to the baselines on MS MARCO dataset.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
articleno = {155},
numpages = {25},
keywords = {Model-based IR, generative model, document retrieval, knowledge distillation, docid representation}
}

@misc{li2023multiviewidentifiersenhancedgenerative,
 title={Multiview Identifiers Enhanced Generative Retrieval}, 
 author={Yongqi Li and Nan Yang and Liang Wang and Furu Wei and Wenjie Li},
 year={2023},
 eprint={2305.16675},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2305.16675}, 
}

@misc{li2023learningrankgenerativeretrieval,
 title={Learning to Rank in Generative Retrieval}, 
 author={Yongqi Li and Nan Yang and Liang Wang and Furu Wei and Wenjie Li},
 year={2023},
 eprint={2306.15222},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2306.15222}, 
}

@misc{tang2024generativeretrievalmeetsmultigraded,
 title={Generative Retrieval Meets Multi-Graded Relevance}, 
 author={Yubao Tang and Ruqing Zhang and Jiafeng Guo and Maarten de Rijke and Wei Chen and Xueqi Cheng},
 year={2024},
 eprint={2409.18409},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2409.18409}, 
}

@inproceedings{Choi_2022, series={CIKM ’22},
   title={SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval},
   url={http://dx.doi.org/10.1145/3511808.3557456},
   DOI={10.1145/3511808.3557456},
   booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
   publisher={ACM},
   author={Choi, Eunseong and Lee, Sunkyung and Choi, Minjin and Ko, Hyeseon and Song, Young-In and Lee, Jongwuk},
   year={2022},
   month=oct, pages={272–282},
   collection={CIKM ’22} }

@misc{biswas2024efficientinterpretableinformationretrieval,
 title={Efficient and Interpretable Information Retrieval for Product Question Answering with Heterogeneous Data}, 
 author={Biplob Biswas and Rajiv Ramnath},
 year={2024},
 eprint={2405.13173},
 archivePrefix={arXiv},
 primaryClass={cs.LG},
 url={https://arxiv.org/abs/2405.13173}, 
}

@misc{gao2021coilrevisitexactlexical,
 title={COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List}, 
 author={Luyu Gao and Zhuyun Dai and Jamie Callan},
 year={2021},
 eprint={2104.07186},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2104.07186}, 
}

@misc{karpukhin2020densepassageretrievalopendomain,
 title={Dense Passage Retrieval for Open-Domain Question Answering}, 
 author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
 year={2020},
 eprint={2004.04906},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2004.04906}, 
}

@article{bm25robertson2009,
author = {Robertson, Stephen and Zaragoza, Hugo},
year = {2009},
month = {01},
pages = {333-389},
title = {The Probabilistic Relevance Framework: BM25 and Beyond},
volume = {3},
journal = {Foundations and Trends in Information Retrieval},
doi = {10.1561/1500000019}
}

@misc{xiong2020approximatenearestneighbornegative,
 title={Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval}, 
 author={Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul Bennett and Junaid Ahmed and Arnold Overwijk},
 year={2020},
 eprint={2007.00808},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2007.00808}, 
}

@misc{li2023constructingtreebasedindexefficient,
 title={Constructing Tree-based Index for Efficient and Effective Dense Retrieval}, 
 author={Haitao Li and Qingyao Ai and Jingtao Zhan and Jiaxin Mao and Yiqun Liu and Zheng Liu and Zhao Cao},
 year={2023},
 eprint={2304.11943},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2304.11943}, 
}

@misc{ni2021largedualencodersgeneralizable,
 title={Large Dual Encoders Are Generalizable Retrievers}, 
 author={Jianmo Ni and Chen Qu and Jing Lu and Zhuyun Dai and Gustavo Hernández Ábrego and Ji Ma and Vincent Y. Zhao and Yi Luan and Keith B. Hall and Ming-Wei Chang and Yinfei Yang},
 year={2021},
 eprint={2112.07899},
 archivePrefix={arXiv},
 primaryClass={cs.IR},
 url={https://arxiv.org/abs/2112.07899}, 
}

@misc{liu2019robertarobustlyoptimizedbert,
 title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
 author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
 year={2019},
 eprint={1907.11692},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/1907.11692}, 
}

@misc{grattafiori2024llama3herdmodels,
 title={The Llama 3 Herd of Models}, 
 author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldst and and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holl and and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Z and and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
 year={2024},
 eprint={2407.21783},
 archivePrefix={arXiv},
 primaryClass={cs.AI},
 url={https://arxiv.org/abs/2407.21783}, 
}

@misc{nogueira2019documentexpansionqueryprediction,
      title={Document Expansion by Query Prediction}, 
      author={Rodrigo Nogueira and Wei Yang and Jimmy Lin and Kyunghyun Cho},
      year={2019},
      eprint={1904.08375},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/1904.08375}, 
}

@article{Cheng_Dou_Zhu_Li_2025, title={Descriptive and Discriminative Document Identifiers for Generative Retrieval}, volume={39}, url={https://ojs.aaai.org/index.php/AAAI/article/view/33253}, DOI={10.1609/aaai.v39i11.33253}, abstractNote={Generative document retrieval is a novel retrieval framework, which represents documents as identifiers (DocID) and retrieves documents by generating DocIDs. It has the advantage of end-to-end optimization over traditional retrieval methods and has attracted much research interest. Nonetheless, the development of efficient and precise DocIDs for document representation remains a pertinent issue within the field. Existing methods for designing DocIDs tend to consider only the relevance of DocIDs to the corresponding documents, while neglecting the ability of the DocIDs to distinguish the corresponding documents from similar ones, which is crucial for the retrieval task. In this paper, we design learnable descriptive and discriminative document Identifiers (D2-DocID) for Generative Retrieval and propose the paired retrieval model D2Gen. The D2-DocID is semantically similar to the corresponding documents (descriptive) and is able to distinguish similar documents (discriminative) in the corpus, thus enhancing retrieval performance. We use a contrastive learning assisted generative retrieval task to enable the model to understand the document and then complete the generative retrieval. We then design a DocID selection method to select DocIDs based on the retrieval model’s understanding of the documents. Our experimental results on the MS MARCO and NQ320k dataset illustrate the effectiveness of the approach.}, number={11}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Cheng, Jiehan and Dou, Zhicheng and Zhu, Yutao and Li, Xiaoxi}, year={2025}, month={Apr.}, pages={11518-11526} }

@misc{naous2024havingbeerprayermeasuring,
 title={Having Beer after Prayer? Measuring Cultural Bias in Large Language Models}, 
 author={Tarek Naous and Michael J. Ryan and Alan Ritter and Wei Xu},
 year={2024},
 eprint={2305.14456},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2305.14456}, 
}

@misc{aowal2023detectingnaturallanguagebiases,
 title={Detecting Natural Language Biases with Prompt-based Learning}, 
 author={Md Abdul Aowal and Maliha T Islam and Priyanka Mary Mammen and Sandesh Shetty},
 year={2023},
 eprint={2309.05227},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2309.05227}, 
}

@article{10.1145/3597307,
author = {Navigli, Roberto and Conia, Simone and Ross, Bj\"{o}rn},
title = {Biases in Large Language Models: Origins, Inventory, and Discussion},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1936-1955},
url = {https://doi.org/10.1145/3597307},
doi = {10.1145/3597307},
abstract = {In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.},
journal = {J. Data and Information Quality},
month = jun,
articleno = {10},
numpages = {21},
keywords = {language models, Bias in NLP}
}

@misc{hofstätter2021efficientlyteachingeffectivedense,
      title={Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling}, 
      author={Sebastian Hofstätter and Sheng-Chieh Lin and Jheng-Hong Yang and Jimmy Lin and Allan Hanbury},
      year={2021},
      eprint={2104.06967},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2104.06967}, 
}

@misc{valluri2024scalingvocabularynonautoregressivemodels,
      title={Scaling the Vocabulary of Non-autoregressive Models for Efficient Generative Retrieval}, 
      author={Ravisri Valluri and Akash Kumar Mohankumar and Kushal Dave and Amit Singh and Jian Jiao and Manik Varma and Gaurav Sinha},
      year={2024},
      eprint={2406.06739},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.06739}, 
}

@misc{zhao2026diffugrgenerativedocumentretrieval,
      title={DiffuGR: Generative Document Retrieval with Diffusion Language Models}, 
      author={Xinpeng Zhao and Zhaochun Ren and Yukun Zhao and Zhenyang Li and Mengqi Zhang and Jun Feng and Ran Chen and Ying Zhou and Zhumin Chen and Shuaiqiang Wang and Dawei Yin and Xin Xin},
      year={2026},
      eprint={2511.08150},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2511.08150}, 
}

@inproceedings{joshi-etal-2017-triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar and Choi, Eunsol and Weld, Daniel and Zettlemoyer, Luke",
    editor = "Barzilay, Regina and Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147/",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study."
}

@misc{wang2025mindrefmimickinghumanmemory,
      title={MindRef: Mimicking Human Memory for Hierarchical Reference Retrieval with Fine-Grained Location Awareness}, 
      author={Ye Wang and Xinrun Xu and Zhiming Ding},
      year={2025},
      eprint={2402.17010},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.17010}, 
}

@misc{petroni2021kiltbenchmarkknowledgeintensive,
 title={KILT: a Benchmark for Knowledge Intensive Language Tasks}, 
 author={Fabio Petroni and Aleksandra Piktus and Angela Fan and Patrick Lewis and Majid Yazdani and Nicola De Cao and James Thorne and Yacine Jernite and Vladimir Karpukhin and Jean Maillard and Vassilis Plachouras and Tim Rocktäschel and Sebastian Riedel},
 year={2021},
 eprint={2009.02252},
 archivePrefix={arXiv},
 primaryClass={cs.CL},
 url={https://arxiv.org/abs/2009.02252}, 
}


@inproceedings{zhang-etal-2025-multi-level,
    title = "Multi-level Relevance Document Identifier Learning for Generative Retrieval",
    author = "Zhang, Fuwei  and
      Liu, Xiaoyu  and
      Jia, Xinyu  and
      Zhang, Yingfei  and
      Zhang, Shuai  and
      Li, Xiang  and
      Zhuang, Fuzhen  and
      Lin, Wei  and
      Zhang, Zhao",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.497/",
    doi = "10.18653/v1/2025.acl-long.497",
    pages = "10066--10080",
    ISBN = "979-8-89176-251-0",
    abstract = "Generative Retrieval (GR) introduces a new information retrieval paradigm that directly generates unique document identifiers (DocIDs). The key challenge of GR lies in creating effective yet discrete DocIDs that preserve semantic relevance for similar documents while differentiating dissimilar ones. However, existing methods generate DocIDs solely based on the textual content of documents, which may result in DocIDs with weak semantic connections for similar documents due to variations in expression. Therefore, we propose using queries as a bridge to connect documents with varying relevance levels for learning improved DocIDs. In this paper, we propose **M**ulti-l**E**vel **R**elevance document identifier learning for **G**enerative r**E**trieval (MERGE), a novel approach that utilizes multi-level document relevance to learn high-quality DocIDs. MERGE incorporates three modules: a multi-relevance query-document alignment module to effectively align document representations with related queries, an outer-level contrastive learning module to capture binary-level relevance, and an inner-level multi-level relevance learning module to distinguish documents with different relevance levels. Our approach encodes rich hierarchical semantic information and maintains uniqueness across documents. Experimental results on real-world multilingual e-commerce search datasets demonstrate that MERGE significantly outperforms existing methods, underscoring its effectiveness. The source code is available at {\ensuremath{<}}https://github.com/zhangfw123/MERGE{\ensuremath{>}}."
}