@misc{bevilacqua2022autoregressivesearchenginesgenerating,
      title={Autoregressive Search Engines: Generating Substrings as Document Identifiers}, 
      author={Michele Bevilacqua and Giuseppe Ottaviano and Patrick Lewis and Wen-tau Yih and Sebastian Riedel and Fabio Petroni},
      year={2022},
      eprint={2204.10628},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.10628}, 
}

@misc{massarelli2020decodingstrategiesaffectverifiability,
      title={How Decoding Strategies Affect the Verifiability of Generated Text}, 
      author={Luca Massarelli and Fabio Petroni and Aleksandra Piktus and Myle Ott and Tim Rocktäschel and Vassilis Plachouras and Fabrizio Silvestri and Sebastian Riedel},
      year={2020},
      eprint={1911.03587},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1911.03587}, 
}

@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026/",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature."
}

@article{Metzler_2021,
   title={Rethinking search: making domain experts out of dilettantes},
   volume={55},
   ISSN={0163-5840},
   url={http://dx.doi.org/10.1145/3476415.3476428},
   DOI={10.1145/3476415.3476428},
   number={1},
   journal={ACM SIGIR Forum},
   publisher={Association for Computing Machinery (ACM)},
   author={Metzler, Donald and Tay, Yi and Bahri, Dara and Najork, Marc},
   year={2021},
   month=jun, pages={1–27} }

@article{Ji_2023,
   title={Survey of Hallucination in Natural Language Generation},
   volume={55},
   ISSN={1557-7341},
   url={http://dx.doi.org/10.1145/3571730},
   DOI={10.1145/3571730},
   number={12},
   journal={ACM Computing Surveys},
   publisher={Association for Computing Machinery (ACM)},
   author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
   year={2023},
   month=mar, pages={1–38} }

@misc{zeng2024planningaheadgenerativeretrieval,
      title={Planning Ahead in Generative Retrieval: Guiding Autoregressive Generation through Simultaneous Decoding}, 
      author={Hansi Zeng and Chen Luo and Hamed Zamani},
      year={2024},
      eprint={2404.14600},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2404.14600}, 
}

@misc{zhang2024generativeretrievaltermset,
      title={Generative Retrieval via Term Set Generation}, 
      author={Peitian Zhang and Zheng Liu and Yujia Zhou and Zhicheng Dou and Fangchao Liu and Zhao Cao},
      year={2024},
      eprint={2305.13859},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2305.13859}, 
}

@misc{stahlberg2019nmtsearcherrorsmodel,
      title={On NMT Search Errors and Model Errors: Cat Got Your Tongue?}, 
      author={Felix Stahlberg and Bill Byrne},
      year={2019},
      eprint={1908.10090},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1908.10090}, 
}

@inproceedings{Zhou2005BeamStackSI,
  title={Beam-Stack Search: Integrating Backtracking with Beam Search},
  author={R. Zhou and Eric A. Hansen},
  booktitle={International Conference on Automated Planning and Scheduling},
  year={2005},
  url={https://api.semanticscholar.org/CorpusID:11314454}
}

@misc{sun2023learningtokenizegenerativeretrieval,
      title={Learning to Tokenize for Generative Retrieval}, 
      author={Weiwei Sun and Lingyong Yan and Zheng Chen and Shuaiqiang Wang and Haichao Zhu and Pengjie Ren and Zhumin Chen and Dawei Yin and Maarten de Rijke and Zhaochun Ren},
      year={2023},
      eprint={2304.04171},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2304.04171}, 
}

@inproceedings{Chen_2023, series={CIKM ’23},
   title={Continual Learning for Generative Retrieval over Dynamic Corpora},
   url={http://dx.doi.org/10.1145/3583780.3614821},
   DOI={10.1145/3583780.3614821},
   booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
   publisher={ACM},
   author={Chen, Jiangui and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
   year={2023},
   month=oct, pages={306–315},
   collection={CIKM ’23} }


@misc{zhang2025replicationexplorationgenerativeretrieval,
      title={Replication and Exploration of Generative Retrieval over Dynamic Corpora}, 
      author={Zhen Zhang and Xinyu Ma and Weiwei Sun and Pengjie Ren and Zhumin Chen and Shuaiqiang Wang and Dawei Yin and Maarten de Rijke and Zhaochun Ren},
      year={2025},
      eprint={2504.17519},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2504.17519}, 
}

@misc{liu2024robustnessgenerativeinformationretrieval,
      title={On the Robustness of Generative Information Retrieval Models}, 
      author={Yu-An Liu and Ruqing Zhang and Jiafeng Guo and Changjiang Zhou and Maarten de Rijke and Xueqi Cheng},
      year={2024},
      eprint={2412.18768},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2412.18768}, 
}

@misc{yuan2024generativedenseretrievalmemory,
      title={Generative Dense Retrieval: Memory Can Be a Burden}, 
      author={Peiwen Yuan and Xinglin Wang and Shaoxiong Feng and Boyuan Pan and Yiwei Li and Heda Wang and Xupeng Miao and Kan Li},
      year={2024},
      eprint={2401.10487},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2401.10487}, 
}

@misc{pradeep2023doesgenerativeretrievalscale,
      title={How Does Generative Retrieval Scale to Millions of Passages?}, 
      author={Ronak Pradeep and Kai Hui and Jai Gupta and Adam D. Lelkes and Honglei Zhuang and Jimmy Lin and Donald Metzler and Vinh Q. Tran},
      year={2023},
      eprint={2305.11841},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2305.11841}, 
}

@misc{tay2022transformermemorydifferentiablesearch,
      title={Transformer Memory as a Differentiable Search Index}, 
      author={Yi Tay and Vinh Q. Tran and Mostafa Dehghani and Jianmo Ni and Dara Bahri and Harsh Mehta and Zhen Qin and Kai Hui and Zhe Zhao and Jai Gupta and Tal Schuster and William W. Cohen and Donald Metzler},
      year={2022},
      eprint={2202.06991},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.06991}, 
}

@misc{mehta2023dsiupdatingtransformermemory,
      title={DSI++: Updating Transformer Memory with New Documents}, 
      author={Sanket Vaibhav Mehta and Jai Gupta and Yi Tay and Mostafa Dehghani and Vinh Q. Tran and Jinfeng Rao and Marc Najork and Emma Strubell and Donald Metzler},
      year={2023},
      eprint={2212.09744},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.09744}, 
}

@misc{nguyen2023generativeretrievaldenseretrieval,
      title={Generative Retrieval as Dense Retrieval}, 
      author={Thong Nguyen and Andrew Yates},
      year={2023},
      eprint={2306.11397},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2306.11397}, 
}

@misc{zeng2023scalableeffectivegenerativeinformation,
      title={Scalable and Effective Generative Information Retrieval}, 
      author={Hansi Zeng and Chen Luo and Bowen Jin and Sheikh Muhammad Sarwar and Tianxin Wei and Hamed Zamani},
      year={2023},
      eprint={2311.09134},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2311.09134}, 
}

@inproceedings{10.1145/3589335.3641239,
author = {Tang, Yubao and Zhang, Ruqing and Sun, Weiwei and Guo, Jiafeng and De Rijke, Maarten},
title = {Recent Advances in Generative Information Retrieval},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641239},
doi = {10.1145/3589335.3641239},
abstract = {Generative retrieval (GR) has witnessed significant growth recently in the area of information retrieval. Compared to the traditional "index-retrieve-then-rank'' pipeline, the GR paradigm aims to consolidate all information within a corpus into a single model. Typically, a sequence-to-sequence model is trained to directly map a query to its relevant document identifiers (i.e., docids). This tutorial offers an introduction to the core concepts of the GR paradigm and a comprehensive overview of recent advances in its foundations and applications. We start by providing preliminary information covering foundational aspects and problem formulations of GR. Then, our focus shifts towards recent progress in docid design, training approaches, inference strategies, and applications of GR. We end by outlining challenges and issuing a call for future GR research.This tutorial is intended to be beneficial to both researchers and industry practitioners interested in developing novel GR solutions or applying them in real-world scenarios.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1238–1241},
numpages = {4},
location = {Singapore, Singapore},
series = {WWW '24}
}

@misc{ross2021evaluatinginterpretabilitygenerativemodels,
      title={Evaluating the Interpretability of Generative Models by Interactive Reconstruction}, 
      author={Andrew Slavin Ross and Nina Chen and Elisa Zhao Hang and Elena L. Glassman and Finale Doshi-Velez},
      year={2021},
      eprint={2102.01264},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2102.01264}, 
}

@misc{li2025matchinggenerationsurveygenerative,
      title={From Matching to Generation: A Survey on Generative Information Retrieval}, 
      author={Xiaoxi Li and Jiajie Jin and Yujia Zhou and Yuyao Zhang and Peitian Zhang and Yutao Zhu and Zhicheng Dou},
      year={2025},
      eprint={2404.14851},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2404.14851}, 
}

@misc{kuo2024surveygenerativeinformationretrieval,
      title={A Survey of Generative Information Retrieval}, 
      author={Tzu-Lin Kuo and Tzu-Wei Chiu and Tzung-Sheng Lin and Sheng-Yang Wu and Chao-Wei Huang and Yun-Nung Chen},
      year={2024},
      eprint={2406.01197},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2406.01197}, 
}

@misc{tang2024listwisegenerativeretrievalmodels,
      title={Listwise Generative Retrieval Models via a Sequential Learning Process}, 
      author={Yubao Tang and Ruqing Zhang and Jiafeng Guo and Maarten de Rijke and Wei Chen and Xueqi Cheng},
      year={2024},
      eprint={2403.12499},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2403.12499}, 
}

@misc{yang2023autosearchindexerendtoend,
      title={Auto Search Indexer for End-to-End Document Retrieval}, 
      author={Tianchi Yang and Minghui Song and Zihan Zhang and Haizhen Huang and Weiwei Deng and Feng Sun and Qi Zhang},
      year={2023},
      eprint={2310.12455},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2310.12455}, 
}

@article{10.1145/3603167,
author = {Zhou, Yujia and Yao, Jing and Dou, Zhicheng and Tu, Yiteng and Wu, Ledell and Chua, Tat-Seng and Wen, Ji-Rong},
title = {ROGER: Ranking-Oriented Generative Retrieval},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3603167},
doi = {10.1145/3603167},
abstract = {In recent years, various dense retrieval methods have been developed to improve the performance of search engines with a vectorized index. However, these approaches require a large pre-computed index and have a limited capacity to memorize all semantics in a document within a single vector. To address these issues, researchers have explored end-to-end generative retrieval models that use a seq-to-seq generative model to directly return identifiers of relevant documents. Although these models have been effective, they are often trained with the MLE method. It only encourages the model to assign a high probability to the relevant document identifier, ignoring the relevance comparisons of other documents. This may lead to performance degradation in ranking tasks, where the core is to compare the relevance between documents. To address this issue, we propose a ranking-oriented generative retrieval model that incorporates relevance signals to better estimate the relative relevance of different documents in ranking tasks. Based upon the analysis of the optimization objectives of dense retrieval and generative retrieval, we propose utilizing dense retrieval to provide relevance feedback for generative retrieval. Under an alternate training framework, the generative retrieval model gradually acquires higher-quality ranking signals to optimize the model. Experimental results show that our approach increasing Recall@1 by 12.9\% with respect to the baselines on MS MARCO dataset.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
articleno = {155},
numpages = {25},
keywords = {Model-based IR, generative model, document retrieval, knowledge distillation, docid representation}
}

@misc{li2023multiviewidentifiersenhancedgenerative,
      title={Multiview Identifiers Enhanced Generative Retrieval}, 
      author={Yongqi Li and Nan Yang and Liang Wang and Furu Wei and Wenjie Li},
      year={2023},
      eprint={2305.16675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.16675}, 
}

@misc{li2023learningrankgenerativeretrieval,
      title={Learning to Rank in Generative Retrieval}, 
      author={Yongqi Li and Nan Yang and Liang Wang and Furu Wei and Wenjie Li},
      year={2023},
      eprint={2306.15222},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.15222}, 
}

@misc{tang2024generativeretrievalmeetsmultigraded,
      title={Generative Retrieval Meets Multi-Graded Relevance}, 
      author={Yubao Tang and Ruqing Zhang and Jiafeng Guo and Maarten de Rijke and Wei Chen and Xueqi Cheng},
      year={2024},
      eprint={2409.18409},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2409.18409}, 
}

@inproceedings{Choi_2022, series={CIKM ’22},
   title={SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval},
   url={http://dx.doi.org/10.1145/3511808.3557456},
   DOI={10.1145/3511808.3557456},
   booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
   publisher={ACM},
   author={Choi, Eunseong and Lee, Sunkyung and Choi, Minjin and Ko, Hyeseon and Song, Young-In and Lee, Jongwuk},
   year={2022},
   month=oct, pages={272–282},
   collection={CIKM ’22} }

@misc{biswas2024efficientinterpretableinformationretrieval,
      title={Efficient and Interpretable Information Retrieval for Product Question Answering with Heterogeneous Data}, 
      author={Biplob Biswas and Rajiv Ramnath},
      year={2024},
      eprint={2405.13173},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.13173}, 
}

@misc{gao2021coilrevisitexactlexical,
      title={COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List}, 
      author={Luyu Gao and Zhuyun Dai and Jamie Callan},
      year={2021},
      eprint={2104.07186},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2104.07186}, 
}

@misc{karpukhin2020densepassageretrievalopendomain,
      title={Dense Passage Retrieval for Open-Domain Question Answering}, 
      author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
      year={2020},
      eprint={2004.04906},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.04906}, 
}

@misc{xiong2020approximatenearestneighbornegative,
      title={Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval}, 
      author={Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul Bennett and Junaid Ahmed and Arnold Overwijk},
      year={2020},
      eprint={2007.00808},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2007.00808}, 
}

@misc{li2023constructingtreebasedindexefficient,
      title={Constructing Tree-based Index for Efficient and Effective Dense Retrieval}, 
      author={Haitao Li and Qingyao Ai and Jingtao Zhan and Jiaxin Mao and Yiqun Liu and Zheng Liu and Zhao Cao},
      year={2023},
      eprint={2304.11943},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2304.11943}, 
}

@misc{ni2021largedualencodersgeneralizable,
      title={Large Dual Encoders Are Generalizable Retrievers}, 
      author={Jianmo Ni and Chen Qu and Jing Lu and Zhuyun Dai and Gustavo Hernández Ábrego and Ji Ma and Vincent Y. Zhao and Yi Luan and Keith B. Hall and Ming-Wei Chang and Yinfei Yang},
      year={2021},
      eprint={2112.07899},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2112.07899}, 
}